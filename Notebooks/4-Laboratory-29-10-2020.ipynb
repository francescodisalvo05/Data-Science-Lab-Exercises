{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-Laboratory-29-10-2020 L\n",
    "\n",
    "| Credits to the authors of the exercises: Andrea Pasini, Giuseppe Attanasio, Flavio Giobergia\n",
    "| Master of Science in Data Science and Engineering, Politecnico di Torino, A.A. 2020-21\n",
    "\n",
    "# KNN design and Implementation\n",
    "In this exercise, you will implement your own version of the the K-Nearest Neighbors algorithm, and you will use it to assign a Iris species (i.e. a label) to flowers whose species is unknown. The KNN algorithm is straightforward. Suppose that some measurements (i.e. records) and the irrelative species are known in advance. Then, whenever we want to label a new flower, we look at the Kmost similar points (a.k.a. neighbors) and assign a label accordingly. The simplest solution is using amajority voting scheme: if the majority of the neighborsvotesfor a label, we will go for it. This approachis naive only at first sight: the local similarity assumed by KNN happens to be roughly true. Even thoughthis reasoning does not generalize well1, the KNN provides a valid baseline for your tasks.\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Load the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3            4\n",
       "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
       "1  4.9  3.0  1.4  0.2  Iris-setosa"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I import in adive the libraries that I'll using during this lab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\",header=None)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Let’s identify a portion of our data for which we will try to guess the species. Randomly select 20% of the records and store the first four columns (i.e. the features representing each flower) into atwo-dimensional numpy array of shape N×C, you can call it X_test. For the same records, store the last column (i.e. the one with the species values) into another array,namely y_test. This is the data that will be used to test the accuracy of your KNN implementationand its correct functioning (i.e. the testing data)\n",
    "\n",
    "3. Store the remaining 80% of the records in the same way. In this case, use the namesX_trainandy_trainfor the arrays. This is the data that your model will use as ground-truth knowledge (i.e. thetraining data)\n",
    "\n",
    "I know the possibility to do easily with scikit learn, but since we didn't study it already, I'll do it without any particular help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I put everything in one script because it's easier to \n",
    "# test the algorithm with different samples\n",
    "\n",
    "X_test = df.sample(int(len(df)/5)) #20% means len/5\n",
    "y_test = X_test[4] # pandas' columns are already numpy arrays\n",
    "X_test = X_test.drop(columns=[4])\n",
    "X_train = df[[0,1,2,3]].drop(X_test.index)\n",
    "y_train  = df[4].drop(y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3\n",
       "64  5.6  2.9  3.6  1.3\n",
       "88  5.6  3.0  4.1  1.3\n",
       "90  5.5  2.6  4.4  1.2\n",
       "15  5.7  4.4  1.5  0.4\n",
       "28  5.2  3.4  1.4  0.2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64    Iris-versicolor\n",
       "88    Iris-versicolor\n",
       "90    Iris-versicolor\n",
       "15        Iris-setosa\n",
       "28        Iris-setosa\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 64,  88,  90,  15,  28,   0,  73,  29, 103,  47, 122, 108, 138,\n",
       "             44,  27,  11,  80,  58, 144, 140,  53,  18,  25,  23,  39,   8,\n",
       "             13,  85, 110,  75],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index used\n",
    "X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3\n",
       "1  4.9  3.0  1.4  0.2\n",
       "2  4.7  3.2  1.3  0.2\n",
       "3  4.6  3.1  1.5  0.2\n",
       "4  5.0  3.6  1.4  0.2\n",
       "5  5.4  3.9  1.7  0.4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    Iris-setosa\n",
       "2    Iris-setosa\n",
       "3    Iris-setosa\n",
       "4    Iris-setosa\n",
       "5    Iris-setosa\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Implement now the KNN algorithm and expose it as a Python class. Implement the fit method first. Here, you should only keep track of the main attributes that will be used by the algorithm. In this version of the algorithm, does the KNN need to store all the samples of X_train and y_train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" The general structure, I'll complete later on anothe \"\"\"\n",
    "class KNearestNeighbors:\n",
    "    def __init__(self, k, distance_metric=\"euclidean\"):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "            Store the'prior knowledge' of you model that will be used \n",
    "            to predict new labels.\n",
    "            \n",
    "            :param X : input data points, ndarray, shape = (R,C).\n",
    "            :param y : input labels, ndarray, shape = (R,).\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "            Run the KNN classification on X.\n",
    "            \n",
    "            :param X: input data points, ndarray, shape = (N,C).\n",
    "            :return: labels : ndarray, shape = (N,).\n",
    "        \"\"\"\n",
    "        pass# TODO: implement it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, I think in this case we cannot say precisely, but I think we will answer later and we'll say if we notice a possible underfitting or overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. To identify the K closest points, or neighbors, a notion of distance is required. Your implementation must support three different distance definitions. Given two n-dimensional points p= (p1, p2, . . . , pn) and q= (q1, q2, . . . , qn), the euclidean distance is defined as\n",
    "\n",
    "<center>$ed(p,q) = \\sqrt{(\\sum_{i=1}^{n} (p_i - q_i)^2} $</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second distance function is the cosine distance, which is defined as: \n",
    "\n",
    "<center>$cd(p,q) = 1 - |cs(p,q)|$</center>\n",
    "\n",
    "where <u>cs</u> is the cosine similarity, defined as:\n",
    "\n",
    "<center>  $ cs(p,q) = \\frac {\\sum_{i=1}^{n} p_iq_i}{\\sqrt{(\\sum_{i=1}^{n}p_i^2)}\\sqrt{\\sum_{i=1}^{n}q_i^2}}$ </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third distance is the Manhattan distance. The distance is defined as:\n",
    "\n",
    "<center>$md(p,q) = \\sum_{i=1}^{n} | p_i - q_i | $</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def euclidean(a,b):\n",
    "    return np.sqrt(np.sum((a-b)**2,axis=1))\n",
    "\n",
    "def cosine(a,b):\n",
    "    cs = np.sum((a*b),axis=1)/(np.sqrt(np.sum(a**2))*np.sqrt(np.sum(b**2,axis=1)))       \n",
    "    return 1 - abs(cs)\n",
    "\n",
    "def manhattan(a,b):\n",
    "    return np.sum(abs(a-b),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Implement thepredict method. The function receives as input a numpy array with N rows and C columns, corresponding to N flowers. The method assigns one of the three Iris species to each row using the KNN algorithm, and returns them as a numpy array. For the actual implementation, apply the identify K neighbors using the distance specified by the parameters k and distance passed to the constructor. Then, assign the label using a majority voting scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Now let’s fit the KNN model with the X_train and y_train data. Then, try to use your KNN model to predict the species for each record in X_test and store them in a nupy array called y_pred. Check how many Iris species in the array y_pred have been guessed correctly with respect to theo nes in y_test. A prediction is correct if y_pred[i] == y_test[i]. The ratio between the number of correct guesses and the total number of guesses is known as accuracy. If all labels are assigned correctly ((y_pred == y_test).all() == True), the accuracy of the model is 100%. Instead, if none of the guessed species corresponds to the real one ((y_pred == y_test).any() == False),the accuracy is 0%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestNeighbors:\n",
    "    \n",
    "    def __init__(self, k, distance_metric=\"euclidean\"):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def predict(self, X):\n",
    "            \n",
    "        distances_list = list()\n",
    "\n",
    "        for index, row in X.iterrows():\n",
    "            \n",
    "            if self.distance_metric == \"euclidean\":\n",
    "                distances = euclidean(row,self.X)\n",
    "            \n",
    "            elif self.distance_metric == \"cosine\":\n",
    "                distances = cosine(row,self.X)\n",
    "            \n",
    "            elif self.distance_metric == \"manhattan\":\n",
    "                distances = manhattan(row,self.X)\n",
    "            else:\n",
    "                print(\"** ERRORE **\")\n",
    "                return \n",
    "\n",
    "            order = np.argsort(distances)\n",
    "            topk = order[order < self.k]\n",
    "\n",
    "            top_labels = self.y[topk.index]\n",
    "            dic = {'Iris-setosa':0, 'Iris-versicolor':0, 'Iris-virginica':0}\n",
    "\n",
    "            for y in top_labels:\n",
    "                dic[y] += 1\n",
    "\n",
    "            dic = {k: v for k, v in sorted(dic.items(), key=lambda item: item[1])}\n",
    "            distances_list.append(list(dic.keys())[2])\n",
    "                \n",
    "        return np.array(distances_list)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  70.0 %\n"
     ]
    }
   ],
   "source": [
    "# euclidean, cosine, manhattan\n",
    "a = KNearestNeighbors(7,\"euclidean\")\n",
    "a.fit(X_train,y_train)\n",
    "y_pred = a.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \", (np.sum(y_pred == y_test))/len(y_pred)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. (*) As a software developer, you might want to increase the functionalities of your product and publish newer versions over time. The better your code is structured and organized, the lower is theeffort to release updates.As such, extend now your KNN implementation by adding the parameterweightsto the constructor. <br /> Change your KNN implementation to accept a new weighting scheme for the labels. Ifweights=\"distance\", weight neighbor votes by the inverse of their distance (for the distance, again, usedistance_metric). Instead, if the default is chosen (weights=\"uniform\"), use the majority voting you already imple-mented \n",
    "\n",
    "I'll copy the previous one in order to specify the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    distance_metric = ['euclidean','cosine','manhattan']\n",
    "    weights = ['uniform','distance']\n",
    "\"\"\"\n",
    "class KNearestNeighbors:\n",
    "    \n",
    "    def __init__(self, k, distance_metric=\"euclidean\",weights=\"uniform\"):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        self.weights = weights\n",
    "        \n",
    "    def measure_distance(self,row,refer):\n",
    "        if self.distance_metric == \"euclidean\":\n",
    "            distances = euclidean(row,refer)\n",
    "        elif self.distance_metric == \"cosine\":\n",
    "            distances = cosine(row,refer)\n",
    "        elif self.distance_metric == \"manhattan\":\n",
    "            distances = manhattan(row,refer)\n",
    "        else:\n",
    "            return \n",
    "        return distances\n",
    "    \n",
    "    def apply_weights(self,distances):\n",
    "        # initialize the dic\n",
    "        dic = {elem : 0 for elem in set(self.y)}\n",
    "        \n",
    "        # pre-save the index of the distances\n",
    "        index  = distances.index\n",
    "        \n",
    "        # get index of top k sorted sequenceù\n",
    "        if self.weights == \"uniform\":\n",
    "            order = np.argsort(distances)[:self.k]\n",
    "        elif self.weights == \"distance\":\n",
    "            order = np.argsort(-(1/distances))[:self.k]\n",
    "        \n",
    "        # get relative lables and check the occurrencies\n",
    "        top_labels = self.y[index[order]] \n",
    "        for y in top_labels:\n",
    "            dic[y] += 1\n",
    "        dic = {k: v for k, v in sorted(dic.items(), key=lambda item: item[1])}\n",
    "        \n",
    "        return list(dic.keys())[len(dic)-1]\n",
    "            \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        distances_list = list()\n",
    "        for index, row in X.iterrows():\n",
    "            \n",
    "            distances = self.measure_distance(row,self.X)\n",
    "            prediction = self.apply_weights(distances)\n",
    "            \n",
    "            distances_list.append(prediction)\n",
    "                \n",
    "        return np.array(distances_list)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = KNearestNeighbors(5,\"euclidean\",\"distance\")\n",
    "test.fit(X_train,y_train)\n",
    "y_pred = a.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  70.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", (np.sum(y_pred == y_test))/len(y_pred)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. (*) Test the modularity of the implementation applying it on a different dataset. Ideally, you shouldnot change the code of your KNN python class.\n",
    "    - Download the MNIST dataset and sample only 100 points per digit. You will end up with adataset of 1000 samples. \n",
    "    - Define again four numpy arrays as you did in Exercises 2 and 3.\n",
    "    - Apply your KNN as you did for the Iris dataset.\n",
    "    - Evaluate the accuracy on MNIST’s y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9    ...  775  776  777  \\\n",
       "0       7    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "1       2    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2       1    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "4       4    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "9995    2    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "9996    3    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "9997    4    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "9998    5    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "9999    6    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "\n",
       "      778  779  780  781  782  783  784  \n",
       "0       0    0    0    0    0    0    0  \n",
       "1       0    0    0    0    0    0    0  \n",
       "2       0    0    0    0    0    0    0  \n",
       "3       0    0    0    0    0    0    0  \n",
       "4       0    0    0    0    0    0    0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  \n",
       "9995    0    0    0    0    0    0    0  \n",
       "9996    0    0    0    0    0    0    0  \n",
       "9997    0    0    0    0    0    0    0  \n",
       "9998    0    0    0    0    0    0    0  \n",
       "9999    0    0    0    0    0    0    0  \n",
       "\n",
       "[10000 rows x 785 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_MNIST = pd.read_csv('../Datasets/mnist_test.csv', header=None)\n",
    "df_MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get just 100 points for digit\n",
    "\n",
    "df_MNIST_edited = df_MNIST[df_MNIST[0] == 0][:100]\n",
    "for i in range(1,10):\n",
    "    df_MNIST_edited = df_MNIST_edited.append(df_MNIST[df_MNIST[0] == i][:100])\n",
    "len(df_MNIST_edited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_2 = df_MNIST_edited.sample(int(len(df_MNIST_edited)/5)) #20% means len/5\n",
    "y_test_2 = X_test_2[0] # pandas' columns are already numpy arrays\n",
    "X_test_2 = X_test_2.drop(columns=[0])\n",
    "\n",
    "X_train_2 = df_MNIST_edited.drop(X_test_2.index)\n",
    "X_train_2 = X_train_2.drop(columns=[0])\n",
    "y_train_2  = df_MNIST_edited[0].drop(y_test_2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  84.5 %\n"
     ]
    }
   ],
   "source": [
    "mnist_knn = KNearestNeighbors(5,\"euclidean\",\"distance\")\n",
    "mnist_knn.fit(X_train_2,y_train_2)\n",
    "y_pred_2 = mnist_knn.predict(X_test_2)\n",
    "\n",
    "print(\"Accuracy: \",(np.sum(y_pred_2 == y_test_2))/len(y_pred_2)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. (*) The choice of parameters like k,distance_metric or weightsis part of your data analy sispipeline: the process is typically known as validation. You will learn more about algorithm validationin theory lectures.For now, evaluate the accuracy scores achieved by your KNN with different parameter values. Then,try to identify which is the best configuration, for both Iris and MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [3,5]\n",
    "metrics = [\"euclidean\",\"manhattan\",\"cosine\"]\n",
    "weights = [\"uniform\",\"distance\"]\n",
    "\n",
    "accuracy_MNIST = []\n",
    "accuracy_IRIS = []\n",
    "\n",
    "for k in k_values:\n",
    "    for metric in metrics:\n",
    "        for weight in weights:\n",
    "            # IRIS \n",
    "            obj = KNearestNeighbors(k,metric,weight)\n",
    "            obj.fit(X_train,y_train)\n",
    "            y_pred = obj.predict(X_test)\n",
    "            acc = (np.sum(y_pred == y_test))/len(y_pred)*100\n",
    "            accuracy_IRIS.append([k,metric,weight,acc])\n",
    "            \n",
    "            # MNIST\n",
    "            obj = KNearestNeighbors(k,metric,weight)\n",
    "            obj.fit(X_train_2,y_train_2)\n",
    "            y_pred_2 = obj.predict(X_test_2)\n",
    "            acc_2 = (np.sum(y_pred_2 == y_test_2))/len(y_pred_2)*100\n",
    "            accuracy_MNIST.append([k,metric,weight,acc_2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 'euclidean', 'uniform', 100.0],\n",
       " [3, 'euclidean', 'distance', 100.0],\n",
       " [3, 'manhattan', 'uniform', 100.0],\n",
       " [3, 'manhattan', 'distance', 100.0],\n",
       " [3, 'cosine', 'uniform', 100.0],\n",
       " [3, 'cosine', 'distance', 100.0],\n",
       " [5, 'euclidean', 'uniform', 100.0],\n",
       " [5, 'euclidean', 'distance', 100.0],\n",
       " [5, 'manhattan', 'uniform', 100.0],\n",
       " [5, 'manhattan', 'distance', 100.0],\n",
       " [5, 'cosine', 'uniform', 100.0],\n",
       " [5, 'cosine', 'distance', 100.0]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_IRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 'euclidean', 'uniform', 87.0],\n",
       " [3, 'euclidean', 'distance', 87.0],\n",
       " [3, 'manhattan', 'uniform', 85.5],\n",
       " [3, 'manhattan', 'distance', 85.5],\n",
       " [3, 'cosine', 'uniform', 89.0],\n",
       " [3, 'cosine', 'distance', 89.0],\n",
       " [5, 'euclidean', 'uniform', 84.5],\n",
       " [5, 'euclidean', 'distance', 84.5],\n",
       " [5, 'manhattan', 'uniform', 82.0],\n",
       " [5, 'manhattan', 'distance', 82.0],\n",
       " [5, 'cosine', 'uniform', 89.5],\n",
       " [5, 'cosine', 'distance', 89.5]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1-Laboratory-08-10-2020**\n",
    "\n",
    "| Credits to the authors of the exercises: Andrea Pasini, Giuseppe Attanasio, Flavio Giobergia <br />\n",
    "| Master of Science in Data Science and Engineering, Politecnico di Torino, A.A. 2020-21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IRIS Dataset\n",
    "Iris is a particularly famoustoy dataset(i.e. a dataset with a small number of rows and columns, mostlyused for initial small-scale tests and proofs of concept). This specific dataset contains information aboutthe Iris, a genus that includes 260-300 species of plants (you can read more about Iris on Wikipedia). TheIris dataset contains measurements for 150 Iris flowers, each belonging to one of three species: Virginica,Versicolor and Setosa. (50 flowers for each of the three species). These three species all present similarflowers, as you can see in Figure 1.Each of the 150 flowers contained in the Iris dataset is represented by 5 values:\n",
    "- sepal length, in cm\n",
    "- sepal width, in cm\n",
    "- petal length, in cm\n",
    "- petal width, in cm \n",
    "- Iris species, one of: Iris-setosa, Iris-versicolor, Iris-virginica\n",
    "\n",
    "The dataset is available as a Comma-Separated Values (CSV) file. These files are typically used torepresent tabular data. Each row is represented on one of the lines. Each of the rows contains a fixednumber of columns. Each of the columns (in each row) is separated by a comma (,), hence the name.You can read more about CSV files on Wikipedia.The following are 3 lines taken from the Iris dataset. You should check the contents of the CSV fileyourself to get a sense of what CSV files look like <br />\n",
    "- .5.0,3.6,1.4,0.2,Iris-setosa<br />\n",
    "- 6.3,2.3,4.4,1.3,Iris-versicolor<br />\n",
    "- 7.2,3.0,5.8,1.6,Iris-virginica<br />\n",
    "\n",
    "<hr /> \n",
    "\n",
    "### Questions\n",
    "1. Load the previously downloaded Iris dataset as a list of lists (each of the 150 lists should have 5 elements). You can make use of the csv module presented. You can read more about the csv module on the official documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "data = [ [], [], [], [], [] ]\n",
    "head = [\"sepal length\",\"sepal width\",\"petal length\",\"petal width\"]\n",
    "\n",
    "with open('../Datasets/iris.csv') as f:\n",
    "    \n",
    "    for row in csv.reader(f):\n",
    "        \"\"\"\n",
    "            printing \"row\" I noticed that the last row is empty\n",
    "            so I need to get just the ones with 5 attributes\n",
    "        \"\"\"\n",
    "        if len(row) == 5:\n",
    "            \"\"\"\n",
    "                for the other exercise we'll need numbers and not string\n",
    "                but pay attention that the last element have to remain a string\n",
    "                \n",
    "                convert string into float from 0 to 3\n",
    "                element 4 remains \n",
    "            \"\"\"\n",
    "                \n",
    "            for i in range(4):\n",
    "                data[i].append(float(row[i]))\n",
    "            \n",
    "            data[4].append(row[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Compute and print the mean and the standard deviation for each of the 4 measurement columns(i.e. sepal length and width, petal length and width). Remember that, for a given list ofnvaluesx= (x1,x2,...,xn), the mean μ and the standard deviation σ are defined respectively as <img src=\"../Bridge/1.jpg\" width=\"128px\" height=\"auto\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length: \tmean 5.8433 \t std 0.8253\n",
      "sepal width: \tmean 3.0540 \t std 0.4321\n",
      "petal length: \tmean 3.7587 \t std 1.7585\n",
      "petal width: \tmean 1.1987 \t std 0.7606\n"
     ]
    }
   ],
   "source": [
    "def mean(x):\n",
    "    return sum(x) / len(x)\n",
    "\n",
    "def std(x):\n",
    "    u = mean(x)\n",
    "    return (mean([ (x_ - u) ** 2 for x_ in x ])) ** 0.5\n",
    "\n",
    "for i, m in enumerate(head):\n",
    "    print(f\"{m}: \\tmean {mean(data[i]):.4f} \\t std {std(data[i]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Compute and print the mean and the standard deviation for each of the 4 measurement columns,separately for each of the three Iris species (versicolor, virginica and setosa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Iris-setosa', 'Iris-virginica', 'Iris-versicolor'} \n",
      "\n",
      "5.0060 0.3489\n",
      "6.5880 0.6295\n",
      "5.9360 0.5110\n",
      "\n",
      "3.4180 0.3772\n",
      "2.9740 0.3193\n",
      "2.7700 0.3106\n",
      "\n",
      "1.4640 0.1718\n",
      "5.5520 0.5463\n",
      "4.2600 0.4652\n",
      "\n",
      "0.2440 0.1061\n",
      "2.0260 0.2719\n",
      "1.3260 0.1958\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_types = set(['Iris-versicolor', 'Iris-virginica','Iris-setosa'])\n",
    "measurements = [ \"sepal length\", \"sepal width\", \"petal length\", \"petal width\" ]\n",
    "\n",
    "print(iris_types,\"\\n\")\n",
    "\n",
    "for i, m in enumerate(measurements):\n",
    "    for iris_type in iris_types:\n",
    "        \n",
    "        values = [ a for a,b in zip(data[i], data[4]) if b == iris_type ]\n",
    "        print(f\"{mean(values):.4f} {std(values):.4f}\")\n",
    "    \n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. (*) Based on the results of exercises 2 and 3, which of the 4 measurements would you consideringas being the most characterizing one for the three species? (In other words, which measurementwould you consider “best”, if you were to guess the Iris species based only on those four values?)\n",
    "5. (*) Based on the considerations of Exercise 3, assign the flowers with the following measurementsto what you consider would be the most likely species.5.2, 3.1, 4.0, 1.24.9, 2.5, 5.6, 2.05.4, 3.2, 1.9, 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CITYBIKE Dataset\n",
    "\n",
    "Citybik.es is a website that offers an Application Programming Interface (or API, for short) for the usage ofbike-sharing services throughout the world. Among the others, data for one of Turin’s bike sharing system([TO]Bike) is available. For [TO]Bike, the information available is at a “station” granularity. This meansthat all the data available regards the bike stations: some of the useful information available is the stationname, its position (in terms of latitude and longitude), the number of available bikes and the number offree docks. The data is offered in near real-time (i.e. it is updated every 15-30 minutes).The API endpoint to request the data about for the [TO]Bike service is the following: http://api.citybik.es/v2/networks/to-bike\n",
    "\n",
    "<hr />\n",
    "\n",
    "1. Load the previously downloaded Citybik.es dataset as a Python dictionary. You can make use of the json module presented. You can find the full documentation for the json module here. After thedictionary is loaded, explore its contents from an interactive shell.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['network'])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../Datasets/to-bike.json\") as f:\n",
    "    dic = json.load(f)\n",
    "    print(dic.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['company', 'href', 'id', 'location', 'name', 'source', 'stations'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic[\"network\"].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most relevant column is \"stations\". Once it is a list, for seeing the structure, we can just print the first record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'empty_slots': 0,\n",
       " 'extra': {'number': 2,\n",
       "  'reviews': 1671,\n",
       "  'score': 4.6,\n",
       "  'status': 'online',\n",
       "  'uid': '251'},\n",
       " 'free_bikes': 0,\n",
       " 'id': '15af4cdd63c01ecaf5851e36c8faf608',\n",
       " 'latitude': 45.082462,\n",
       " 'longitude': 7.695677,\n",
       " 'name': 'Bologna',\n",
       " 'timestamp': '2020-10-08T12:51:38.002000Z'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic[\"network\"][\"stations\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Count and print the number of active stations (a station is active if its extra.status field is \"online\")\n",
    "\n",
    "Before going deeper, let's see how can we access to the first field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'online'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic[\"network\"][\"stations\"][0][\"extra\"][\"status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online stations:  113\n"
     ]
    }
   ],
   "source": [
    "\"\"\" list comprehenshion \"\"\"\n",
    "active = [ s for s in dic[\"network\"][\"stations\"] if s[\"extra\"][\"status\"] == \"online\"]\n",
    "print(\"Online stations: \", len(active))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Count and print the total number of bikes available (field free_bikes) and the number of free docks(field empty_slots) throughout all stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bikes available:  181\n",
      "Free docks:  669\n"
     ]
    }
   ],
   "source": [
    "bikes_available = 0\n",
    "free_docks = 0\n",
    "\n",
    "for i in enumerate(dic[\"network\"][\"stations\"]):\n",
    "    \"\"\"\n",
    "        the first element is the key's station\n",
    "    \"\"\"\n",
    "    bikes_available += i[1][\"free_bikes\"]\n",
    "    free_docks += i[1][\"empty_slots\"]\n",
    "    \n",
    "print(\"Bikes available: \", bikes_available)\n",
    "print(\"Free docks: \", free_docks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. (*) Given the coordinates (latitude, longitude) of a point (e.g.45.074512,7.694419), identify the closest bike station to it that has available bikes. For computing the distance among two points(given their coordinates), you can use the functiondistance_coords()defined in the code snippetbelow (which is an implementation of the great-circle distance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import cos, acos, sindef \n",
    "\n",
    "distance_coords(lat1, lng1, lat2, lng2):\n",
    "    \"\"\"Compute the distance among two points.\"\"\"\n",
    "    deg2rad = lambda x: x * 3.141592 / 180lat1, lng1, lat2, lng2 = map(deg2rad, [ lat1, lng1, lat2, lng2 ])\n",
    "    R = 6378100 # Radius of the Earth, in meters\n",
    "    return R * acos(sin(lat1) * sin(lat2) + cos(lat1) * cos(lat2) * cos(lng1 - lng2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset\n",
    "\n",
    "The MNIST dataset is another particularly famous dataset. It contains several thousands of hand-writtendigits (0 to 9). Each hand-written digit is contained in a28×288-bit grayscale image. This means thateach digit has 784 (282) pixels, and each pixel has a value that ranges from 0 (black) to 255 (white).Figure 2 shows one such digit.The dataset can be downloaded from the following URL:https://raw.githubusercontent.com/dbdmg/data-science-lab/master/datasets/mnist_test.csvIn this case, MNIST is represented as a CSV file. Similarly to the Iris dataset, each row of the MNISTdatasets represents a digit. For the sake of simplicity, this dataset contains only a small fraction (10,000digits out of70,000) of the real MNIST dataset, which is known as the MNIST test set (you will learn moreon training and test sets). For each digit, 785 values are available: the first one is the numerical valuedepicted in the image (e.g. for Figure 2 it would be 5). The following 784 columns represent the grayscale image in row-major order\n",
    "\n",
    "<hr />\n",
    "\n",
    "1. Load the previously downloaded MNIST dataset. You can make use of the csv module already presented.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "data_mnist = []\n",
    "numbers = []\n",
    "\n",
    "with open('../Datasets/mnist_test.csv') as f:\n",
    "    for cols in csv.reader(f):\n",
    "        numbers.append(int(cols.pop(0)))\n",
    "        \"\"\" \n",
    "            map(int,cols) coverts all the elements of the list from string to int\n",
    "        \"\"\"\n",
    "        data_mnist.append(list(map(int, cols)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a function that, given a position 1≤k≤10,000, prints the k^(th) digit of the dataset (i.e. the k^(th) row of the csv file) as a grid of 28×28characters. More specifically, you should map each range of pixel values to the following characters: <br />\n",
    "• [0,64)→\" \"<br />\n",
    "• [64,128)→\".\"<br />\n",
    "• [128,192)→\"*\"<br />\n",
    "• [192,256)→\"#\"<br />\n",
    "\n",
    "The first step is to generate a random value with the random library. Remember that we saved the numbers into the \"numbers\" list, so we can print the relative number before the grid. \n",
    "The grid is not necessary, in fact we can just add a breakline every 28 elements (i % 28 == 0) and then we can plot the corrispective charachter with many if clauses in cascade. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The random value is: \t 260\n",
      "The k^th number is:\t 8\n",
      "\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                   .#*      \n",
      "               *#######     \n",
      "            .#####   .##    \n",
      "          *####*.     *#.   \n",
      "         ####.        *#.   \n",
      "         ##.        .###.   \n",
      "         #*        .##*     \n",
      "         ##      .##.       \n",
      "         .#*    *##.        \n",
      "          *#..###*          \n",
      "          .#####.           \n",
      "          .###.             \n",
      "         *##*#              \n",
      "        ##*  #*             \n",
      "       .#.   .#.            \n",
      "       .#     .#            \n",
      "       .#.     *#           \n",
      "       .###    .#*          \n",
      "        .###***##*          \n",
      "            *.#*#           \n",
      "                            \n",
      "                            \n",
      "                            "
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "k = random.randint(1,10000)\n",
    "\n",
    "print(\"The random value is: \\t\",k-1)\n",
    "print(\"The k^th number is:\\t\",numbers[k-1])\n",
    "\n",
    "for i,elem in enumerate(data_mnist[k-1]):\n",
    "    \n",
    "    if i % 28 == 0:\n",
    "        print()\n",
    "    \"\"\"\n",
    "        print(\" ... \", end=\"\") allows to print more elements in the same line\n",
    "    \"\"\"\n",
    "    \n",
    "    if elem < 64:\n",
    "        print(\" \",end=\"\")\n",
    "    elif elem < 128:\n",
    "        print(\".\",end=\"\")\n",
    "    elif elem < 192:\n",
    "        print(\"*\",end=\"\")\n",
    "    elif elem < 256:\n",
    "        print(\"#\",end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Compute the Euclidean distance between each pair of the 784-dimensional vectors of the digits at the following positions: 26th,30th,32nd,35th.\n",
    "\n",
    "Firstly, I'd like to start with a toy example, in order to imporove the script step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.23606797749979\n"
     ]
    }
   ],
   "source": [
    "a = [3,2]\n",
    "b = [1,1]\n",
    "\n",
    "d = sum([ (a[i]-b[i])**2 for i in range(len(a))])**0.5\n",
    "\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An intuitive way to execute this calculation is to take the first one and compare it with the following ones, then we take the second one and we compare it with its following and go on.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26,30 \t 2902.3802\n",
      "26,33 \t 2902.3802\n",
      "26,36 \t 2902.3802\n",
      "30,33 \t 2902.3802\n",
      "30,36 \t 2902.3802\n",
      "33,36 \t 2902.3802\n"
     ]
    }
   ],
   "source": [
    "indexes = [25,29,32,35]\n",
    "\n",
    "for i in range(len(indexes)):\n",
    "    for j in range(i+1,len(indexes)):\n",
    "        x = data_mnist[i]\n",
    "        y = data_mnist[j]    \n",
    "        z = sum([ (x[i]-y[i])**2 for i in range(len(x))])**0.5\n",
    "        print(f\"{indexes[i]+1},{indexes[j]+1} \\t {d:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. (*) Based on the distances computed in the previous step and knowing that the digits listed inExercise 3 are (not necessarily in this order)7,0,1,1, can you assign the correct label to each of thedigits of Exercise 3? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. (*) There are 1,135 1’s and 980 0’s in the dataset. For all 0’s and 1’s separately, count the numberof times each of the 784 pixels is black (use 128 as the threshold value). You can do this by buildinga listZand a listO, each containing 784 elements, containing respectively the counts for the 0’s andthe 1’s.Z[i]andO[i]contain the number of times theithpixel was black for either class. For each value i, computeabs(Z[i] - O[i]). The i with the highest value represents the pixel that bestseparates the digits “0” and “1” (i.e. the pixel that is most often black for one class and white for theother). Where is this pixel located within the grid? Why is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "dev_df = pd.read_csv('../Datasets/NYC_Airbnb/development.csv')\n",
    "eval_df = pd.read_csv('../Datasets/NYC_Airbnb/evaluation.csv')\n",
    "labels = eval_df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39116, 16), (9779, 15))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.shape, eval_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    # eliminate unuseful attributes \n",
    "    df = df.drop(columns=[\"name\",\"host_name\",\"last_review\"])\n",
    "\n",
    "    # null values on review_per_month : fill with the average\n",
    "    df['reviews_per_month'].fillna(0, inplace=True)\n",
    "    # z-score on availability_365\n",
    "        \n",
    "    return df\n",
    "\n",
    "def encode_categories(dev, ev, columns):\n",
    "    for column in columns:\n",
    "\n",
    "        # concat both dataframes in order to have the same encoding\n",
    "        # the ones with NaN belong the ev_set\n",
    "        \n",
    "        df = pd.concat([dev,ev])\n",
    "        df[column] = df[column].factorize()[0]\n",
    "        \n",
    "        ev = df[df['price'].isna()].drop(columns=['price'])\n",
    "        dev = df.dropna(subset=['price'])\n",
    "        \n",
    "    return dev, ev\n",
    "\n",
    "def normalize(df,columns):\n",
    "    for col in columns:\n",
    "        df[col]=(df[col]-df[col].mean())/df[col].std(ddof=0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_encode = ['neighbourhood_group', 'room_type','neighbourhood']\n",
    "columns_to_normalize = ['calculated_host_listings_count','number_of_reviews','minimum_nights']\n",
    "\n",
    "dev_df = clean(dev_df)\n",
    "eval_df = clean(eval_df)\n",
    "\n",
    "dev_df_enc, eval_df_enc = encode_categories(dev_df.copy(),eval_df.copy(),columns_to_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39116, 13), (9779, 12))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df_enc.shape, eval_df_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price                             1.000000\n",
       "room_type                         0.204980\n",
       "longitude                         0.148891\n",
       "availability_365                  0.082667\n",
       "calculated_host_listings_count    0.055070\n",
       "reviews_per_month                 0.053285\n",
       "neighbourhood_group               0.049987\n",
       "number_of_reviews                 0.048254\n",
       "minimum_nights                    0.044238\n",
       "latitude                          0.031274\n",
       "host_id                           0.015168\n",
       "neighbourhood                     0.013436\n",
       "id                                0.009273\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(dev_df_enc.corr()['price']).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev = dev_df_enc.price\n",
    "X_dev = dev_df_enc.drop(columns=['price','host_id','neighbourhood'])\n",
    "X_eval = eval_df_enc.drop(columns=['host_id','neighbourhood'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_intercept': True, 'normalize': False}\n",
      "0.07815010096012076\n"
     ]
    }
   ],
   "source": [
    "## LINEAR REGRESSION ##\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def doLinearReg(in_X,in_y):\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    parameters = {'fit_intercept':[True,False], 'normalize':[True,False]}\n",
    "    gs = GridSearchCV(estimator=model,  \n",
    "                         param_grid=parameters,\n",
    "                         scoring='r2',\n",
    "                         cv=5,\n",
    "                         n_jobs=-1)\n",
    "\n",
    "    ## Lastly, finding the best parameters.\n",
    "    gs.fit(in_X, in_y)\n",
    "    best_parameters_LR = gs.best_params_  \n",
    "    best_score_LR = gs.best_score_ \n",
    "    print(best_parameters_LR)\n",
    "    print(best_score_LR)\n",
    "\n",
    "doLinearReg(X_dev,y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed: 133.4min\n",
      "[Parallel(n_jobs=4)]: Done  54 out of  54 | elapsed: 176.8min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    8.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'mse', 'max_features': 'sqrt', 'n_estimators': 500, 'n_jobs': -1, 'random_state': 42}\n",
      "0.16484622075017086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   10.3s finished\n"
     ]
    }
   ],
   "source": [
    "## RANDOM FOREST ##\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def doRandomForest(in_X,in_y):\n",
    "    \n",
    "    model = RandomForestRegressor(n_jobs=4,verbose=True)\n",
    "    \n",
    "    parameters = {\n",
    "        \"n_estimators\": [100, 250, 500],\n",
    "        \"max_features\": [\"auto\", \"sqrt\", \"log2\"]\n",
    "    }\n",
    "    \n",
    "    gs = GridSearchCV(estimator=model,  \n",
    "                         param_grid=parameters,\n",
    "                         scoring='r2',\n",
    "                         cv=3,\n",
    "                         n_jobs=4,\n",
    "                         verbose=True)\n",
    "\n",
    "    \n",
    "    gs.fit(in_X, in_y)\n",
    "    best_parameters = gs.best_params_  \n",
    "    best_score = gs.best_score_ \n",
    "    print(best_parameters)\n",
    "    print(best_score)\n",
    "    \n",
    "    return gs\n",
    "    \n",
    "gs = doRandomForest(X_dev,y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN ON RANDOM FOREST Ã¬\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dev,y_dev,test_size=0.2,random_state=105)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=500,max_features='sqrt')\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2451124419277212\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(y_test,rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features='sqrt', n_estimators=500)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_final = RandomForestRegressor(n_estimators=500,max_features='sqrt')\n",
    "rf_final.fit(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred_final = rf_final.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame( dict(Id = eval_df['id'],\n",
    "                   Predicted = rf_pred_final)\n",
    "            ).to_csv(\"submissionL9_naive.csv\",sep=\",\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FrancescoEnv",
   "language": "python",
   "name": "francescoenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
